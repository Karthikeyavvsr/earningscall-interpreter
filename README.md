<<<<<<< HEAD
# AI-Driven Earnings Call Interpreter
=======
# EarningsPulse: AI-Driven Earnings Call Interpreter ðŸ“ˆ
>>>>>>> 1cb4f09e (ðŸš€ Major v2 Update: Added Smart Fetch, PDF analysis, predictive analytics, advanced charting)

EarningsPulse is a web application built with Python and Streamlit designed to analyze corporate earnings call transcripts, audio files, and financial reports. It leverages various AI and data analysis techniques to extract insights, sentiment, key financial data, and related stock information.

<<<<<<< HEAD
## Features
-  Transcribe earnings call audio files (Whisper)
-  Sentiment and entity extraction
-  Glossary with financial term definitions
-  Chatbot to answer transcript-based questions
-  Real-time stock price insights

## Project Structure
```
notebooks/   â†’ Experimental notebooks (e.g., Google Colab)
src/         â†’ Python scripts for core features
data/        â†’ Sample audio/transcript files
models/      â†’ Any models used or downloaded
utils/       â†’ Helper functions
glossary/    â†’ Glossary definitions (JSON or CSV)
```

## Setup (Coming Soon)
Instructions to run locally and on Colab.
=======
## âœ¨ Features

This application provides a multi-tab interface for comprehensive analysis:

* **ðŸ“‘ Transcript / PDF Viewer:** Upload or paste earnings call transcripts, upload PDF reports, or automatically fetch content using the "Smart Fetch" feature. View the full text content.
* **ðŸ”Š Audio Transcription:** Upload earnings call audio files (MP3, WAV, M4A, etc.) and transcribe them to text using OpenAI's Whisper model.
* **ðŸ“Š Sentiment & Entities:**
    * Calculates multiple sentiment scores (Polarity, Subjectivity, Forward-Looking, Uncertainty, Litigiousness, Confidence, Analyst Q&A).
    * Displays sentiment drift across the document.
    * Identifies and lists Named Entities (Organizations, People, Locations, etc.) using spaCy.
* **ðŸ“˜ Financial Glossary:**
    * Highlights industry-specific financial terms found within the document based on a predefined JSON glossary.
    * Allows users to manually search the glossary.
* **ðŸ’¬ Q&A with Gemini:** Ask natural language questions about the loaded document and receive answers generated by Google's Gemini API based *only* on the provided text context.
* **ðŸ“ˆ Stock Info & Charts:**
    * Automatically attempts to detect the company ticker symbol from the loaded text or user query, with manual override available. Uses `yfinance` and a Finnhub search fallback for name-to-ticker mapping.
    * Fetches and displays key stock data (price, market cap, P/E, sector, etc.) using `yfinance` with a Finnhub quote fallback.
    * Presents interactive stock price charts (Candlestick or Line) using Plotly, with selectable time periods (1D to Max).
* **ðŸ”® Predictive Analytics (Experimental):**
    * Provides *basic, illustrative* stock price trend predictions for different horizons (Intraday, Short-Term, Long-Term).
    * Uses simple models (`LinearRegression`, `ARIMA`) based on historical `yfinance` data.
    * ***Disclaimer: These predictions are experimental demonstrations and should NOT be considered financial advice.***
* **ðŸ“ Summary:**
    * Consolidates key sentiment scores.
    * Attempts to extract mentions of Revenue, Net Income, and Guidance using RegEx patterns.
    * Generates an AI-powered summary of the document upon request (using a Hugging Face model).
    * Displays relevant basic stock information if a ticker is identified.
* **ðŸ” Smart Fetch:**
    * Enter a company name or ticker to automatically attempt fetching the latest earnings data.
    * Tries to identify the ticker from the query.
    * Attempts to find the Investor Relations page and scrape it for relevant document links (PDF/Transcript).
    * Includes a DuckDuckGo search fallback if the primary scraping method fails.
    * ***Disclaimer: This feature relies on web scraping heuristics and may be unreliable due to website changes or anti-scraping measures.***

## ðŸ› ï¸ Tech Stack

* **Language:** Python 3
* **Web Framework:** Streamlit
* **Data Handling:** Pandas, NumPy
* **NLP & AI:**
    * spaCy (NER)
    * TextBlob (Sentiment)
    * Whisper (Transcription)
    * google-generativeai (Q&A)
    * Transformers (Summarization)
* **Financial Data:** yfinance, requests (for Finnhub API)
* **File Handling:** pdfplumber, json
* **Web Scraping:** requests, BeautifulSoup4, duckduckgo-search
* **Plotting:** Plotly
* **Predictive Modeling:** scikit-learn, statsmodels
* **Environment:** venv

## âš™ï¸ Project Structure
earningscall-interpreter/
â”‚
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ secrets.toml        # API Key storage (MUST be created by user)
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ app.py              # Main Streamlit application script
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ chatbot_utils.py    # Gemini Q&A logic
â”‚   â”œâ”€â”€ financials_utils.py # Financial mentions extraction (RegEx)
â”‚   â”œâ”€â”€ glossary_utils.py   # Glossary loading and searching
â”‚   â”œâ”€â”€ pdf_utils.py        # PDF text extraction, AI Summary
â”‚   â”œâ”€â”€ predictive_model_utils.py # Predictive models
â”‚   â”œâ”€â”€ sentiment_utils.py  # Sentiment scoring logic
â”‚   â”œâ”€â”€ stock_info.py       # Ticker detection, stock data fetching (yfinance/Finnhub)
â”‚   â””â”€â”€ web_fetch_utils.py  # Smart Fetch logic (scraping & fallback search)
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ cache/              # Local JSON cache for stock info
â”‚   â””â”€â”€ finance_terms.json  # (Alternative location for glossary)
â”‚
â”œâ”€â”€ glossary/
â”‚   â””â”€â”€ finance_terms.json  # Predefined financial terms glossary
â”‚
â”œâ”€â”€ requirements.txt        # Project dependencies
â””â”€â”€ README.md               # This file
## ðŸš€ Setup & Installation

1.  **Clone the repository:**
    ```bash
    git clone <your-repo-url>
    cd earningscall-interpreter
    ```

2.  **Create and activate a Python virtual environment:**
    ```bash
    # Create (use python3 or python depending on your system)
    python3 -m venv venv
    # Activate
    # macOS/Linux:
    source venv/bin/activate
    # Windows (cmd):
    # venv\Scripts\activate.bat
    # Windows (PowerShell):
    # .\venv\Scripts\Activate.ps1
    ```

3.  **Install dependencies:**
    ```bash
    pip install --upgrade pip
    pip install -r requirements.txt
    ```

4.  **Download spaCy model:**
    ```bash
    python -m spacy download en_core_web_sm
    ```

5.  **System Dependencies:**
    * You might need to install `ffmpeg` on your system for the Whisper audio transcription to work.
        * **macOS:** `brew install ffmpeg`
        * **Ubuntu/Debian:** `sudo apt update && sudo apt install ffmpeg`
        * **Windows:** Download from the official ffmpeg website and add to your system's PATH.

6.  **Configure API Keys:**
    * Create a file named `secrets.toml` inside a directory named `.streamlit` in your project's root folder (`earningscall-interpreter/.streamlit/secrets.toml`).
    * Add your API keys to this file:
        ```toml
        # .streamlit/secrets.toml

        # Required for Q&A feature
        GOOGLE_API_KEY="YOUR_GOOGLE_GEMINI_API_KEY"

        # Optional but recommended for stock data fallback/mapping
        FINNHUB_API_KEY="YOUR_FINNHUB_API_KEY"
        ```
    * Get keys from:
        * Google AI Studio: [https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)
        * Finnhub: [https://finnhub.io/](https://finnhub.io/) (Free tier available)

## â–¶ï¸ Running the Application

Ensure your virtual environment is activated. Then run:

```bash
streamlit run app/app.py
>>>>>>> 1cb4f09e (ðŸš€ Major v2 Update: Added Smart Fetch, PDF analysis, predictive analytics, advanced charting)
